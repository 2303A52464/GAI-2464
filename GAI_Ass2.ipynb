{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfCe0fBxRbJq4N5jRWbJg1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52464/GAI-2464/blob/main/GAI_Ass2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual values and deep learning model predicted values are shown in Table 1. Also compare the results with the outcomes of libraries.**\n",
        "\n",
        "*YActual YP red*\n",
        "\n",
        "20 20.5\n",
        "\n",
        "30 30.3\n",
        "\n",
        "40 40.2\n",
        "\n",
        "50 50.6\n",
        "\n",
        "60 60.7\n",
        "\n",
        "*Tabela 1: YActual Vs. YP red*"
      ],
      "metadata": {
        "id": "YzSq0jHuUPX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_actual = [20, 30, 40, 50, 60]\n",
        "Y_pred = [20.5, 30.3, 40.2, 50.6, 60.7]\n",
        "\n",
        "def mse(y_actual, y_pred):\n",
        "    return sum((a - p) ** 2 for a, p in zip(y_actual, y_pred)) / len(y_actual)\n",
        "\n",
        "def mae(y_actual, y_pred):\n",
        "    return sum(abs(a - p) for a, p in zip(y_actual, y_pred)) / len(y_actual)\n",
        "\n",
        "def rmse(y_actual, y_pred):\n",
        "    return mse(y_actual, y_pred) ** 0.5\n",
        "\n",
        "print(f\"MSE: {mse(Y_actual, Y_pred):.6f}\")\n",
        "print(f\"MAE: {mae(Y_actual, Y_pred):.6f}\")\n",
        "print(f\"RMSE: {rmse(Y_actual, Y_pred):.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPNaI1l3UTCo",
        "outputId": "29739e59-a4eb-4951-df71-05a42047826a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.246000\n",
            "MAE: 0.460000\n",
            "RMSE: 0.495984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQjmbvBRTuyv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. (1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.**\n",
        "\n",
        "**Actual values and deep learning model predicted values are shown in Table 2. Also compare the results with outcome of libraries**\n",
        "\n",
        "*YActual YP red*\n",
        "\n",
        "0 0 1 1 2 0\n",
        "\n",
        "0 0 1 0 2 0\n",
        "\n",
        "0 1 1 2 2 1\n",
        "\n",
        "0 2 1 0 2 2\n",
        "\n",
        "0 2 1 2 2 2\n",
        "\n",
        "*Tabela 2: YActual Vs. YP red*"
      ],
      "metadata": {
        "id": "GL8QeVniUhOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_actual = [\n",
        "    [0, 0, 1, 1, 2, 0],\n",
        "    [0, 0, 1, 0, 2, 0],\n",
        "    [0, 1, 1, 2, 2, 1],\n",
        "    [0, 2, 1, 0, 2, 2],\n",
        "    [0, 2, 1, 2, 2, 2]\n",
        "]\n",
        "\n",
        "Y_pred = [\n",
        "    [0, 0, 1, 1, 2, 0],\n",
        "    [0, 0, 1, 0, 2, 0],\n",
        "    [0, 1, 1, 2, 2, 1],\n",
        "    [0, 2, 1, 0, 2, 2],\n",
        "    [0, 2, 1, 2, 2, 2]\n",
        "]\n",
        "\n",
        "Y_actual_flat = [val for sublist in Y_actual for val in sublist]\n",
        "Y_pred_flat = [val for sublist in Y_pred for val in sublist]\n",
        "\n",
        "def accuracy(y_actual, y_pred):\n",
        "    correct = sum(1 for a, p in zip(y_actual, y_pred) if a == p)\n",
        "    return correct / len(y_actual)\n",
        "\n",
        "def precision_recall_f1(y_actual, y_pred, class_label):\n",
        "    tp = sum(1 for a, p in zip(y_actual, y_pred) if a == class_label and p == class_label)\n",
        "    fp = sum(1 for a, p in zip(y_actual, y_pred) if a != class_label and p == class_label)\n",
        "    fn = sum(1 for a, p in zip(y_actual, y_pred) if a == class_label and p != class_label)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "classes = set(Y_actual_flat)\n",
        "\n",
        "print(f\"Acurácia: {accuracy(Y_actual_flat, Y_pred_flat):.6f}\")\n",
        "for cls in sorted(classes):\n",
        "    p, r, f1 = precision_recall_f1(Y_actual_flat, Y_pred_flat, cls)\n",
        "    print(f\"Classe {cls} -> Precisão: {p:.6f}, Recall: {r:.6f}, F1-score: {f1:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93rNXGPoUteS",
        "outputId": "79964032-0bc9-4fa8-cd2b-1ee532d3171a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 1.000000\n",
            "Classe 0 -> Precisão: 1.000000, Recall: 1.000000, F1-score: 1.000000\n",
            "Classe 1 -> Precisão: 1.000000, Recall: 1.000000, F1-score: 1.000000\n",
            "Classe 2 -> Precisão: 1.000000, Recall: 1.000000, F1-score: 1.000000\n"
          ]
        }
      ]
    }
  ]
}