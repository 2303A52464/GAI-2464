{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOILfphpfCGr4wIb5HXzOpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52464/GAI-2464/blob/main/GAI_Ass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual values and deep learning model predicted values are shown in Table 1. Also compare the results with the outcomes of libraries.**\n",
        "\n",
        "*YActual YP red*\n",
        "\n",
        "20 20.5\n",
        "\n",
        "30 30.3\n",
        "\n",
        "40 40.2\n",
        "\n",
        "50 50.6\n",
        "\n",
        "60 60.7\n",
        "\n",
        "*Tabela 1: YActual Vs. YP red*"
      ],
      "metadata": {
        "id": "cmLrIRrwSsRV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eei08OJ80CS",
        "outputId": "30c4e9ab-836c-4e35-8076-e0891d4e07f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n"
          ]
        }
      ],
      "source": [
        "# Given data\n",
        "actual_values = [20,30,40,50,60]\n",
        "predicted_values = [20.5,30.3,40.2,50.6,60.7]\n",
        "\n",
        "\n",
        "\n",
        "def mean_absolute_error(actual, predicted):\n",
        "    total_error = 0\n",
        "    for a, p in zip(actual, predicted):\n",
        "        total_error += abs(a - p)\n",
        "    return total_error / len(actual)\n",
        "\n",
        "\n",
        "def mean_squared_error(actual, predicted):\n",
        "    total_error = 0\n",
        "    for a, p in zip(actual, predicted):\n",
        "        total_error += (a - p) ** 2\n",
        "    return total_error / len(actual)\n",
        "\n",
        "\n",
        "def root_mean_squared_error(actual, predicted):\n",
        "    mse = mean_squared_error(actual, predicted)\n",
        "    return mse ** 0.5\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(actual_values, predicted_values)\n",
        "mse = mean_squared_error(actual_values, predicted_values)\n",
        "rmse = root_mean_squared_error(actual_values, predicted_values)\n",
        "\n",
        "\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. (1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.**\n",
        "\n",
        "**Actual values and deep learning model predicted values are shown in Table 2. Also compare the results with outcome of libraries**\n",
        "\n",
        "*YActual YP red*\n",
        "\n",
        "0 0 1 1 2 0\n",
        "\n",
        "0 0 1 0 2 0\n",
        "\n",
        "0 1 1 2 2 1\n",
        "\n",
        "0 2 1 0 2 2\n",
        "\n",
        "0 2 1 2 2 2\n",
        "\n",
        "*Tabela 2: YActual Vs. YP red*"
      ],
      "metadata": {
        "id": "By55zfjeXo0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Given actual and predicted values\n",
        "Y_actual = [0, 1, 2, 0, 0, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2]\n",
        "Y_pred = [0, 1, 0, 2, 2, 0, 2, 0, 2, 1, 1, 0, 2, 2, 2]\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def accuracy(y_true, y_pred):\n",
        "    correct = sum(1 for a, p in zip(y_true, y_pred) if a == p)\n",
        "    return correct / len(y_true)\n",
        "\n",
        "# Function to calculate precision, recall, and F1-score for each class\n",
        "def precision_recall_f1(y_true, y_pred, class_label):\n",
        "    tp = sum(1 for a, p in zip(y_true, y_pred) if p == class_label and a == class_label)\n",
        "    fp = sum(1 for a, p in zip(y_true, y_pred) if p == class_label and a != class_label)\n",
        "    fn = sum(1 for a, p in zip(y_true, y_pred) if p != class_label and a == class_label)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Compute metrics from scratch\n",
        "acc = accuracy(Y_actual, Y_pred)\n",
        "precision_per_class = [precision_recall_f1(Y_actual, Y_pred, c)[0] for c in range(3)]\n",
        "recall_per_class = [precision_recall_f1(Y_actual, Y_pred, c)[1] for c in range(3)]\n",
        "f1_per_class = [precision_recall_f1(Y_actual, Y_pred, c)[2] for c in range(3)]\n",
        "\n",
        "# Print results\n",
        "print(\"From Scratch:\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {precision_per_class}\")\n",
        "print(f\"Recall: {recall_per_class}\")\n",
        "print(f\"F1-score: {f1_per_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvWO6_A7XDXC",
        "outputId": "b1981713-49b2-4770-98da-3b98abac787e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From Scratch:\n",
            "Accuracy: 0.3333\n",
            "Precision: [0.2, 0.3333333333333333, 0.42857142857142855]\n",
            "Recall: [0.2, 0.25, 0.5]\n",
            "F1-score: [0.20000000000000004, 0.28571428571428575, 0.4615384615384615]\n"
          ]
        }
      ]
    }
  ]
}